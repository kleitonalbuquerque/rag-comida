# ğŸ RAG Comida

Projeto **RAG (Retrieval-Augmented Generation)** focado em **conteÃºdos culinÃ¡rios**, utilizando **FastAPI**, **PostgreSQL + pgvector** e **embeddings semÃ¢nticos** para permitir buscas por significado (e nÃ£o apenas por palavras-chave).

O objetivo Ã© armazenar textos (receitas, dicas, curiosidades, descriÃ§Ãµes de pratos etc.), gerar embeddings vetoriais e permitir consultas inteligentes que retornem os conteÃºdos mais relevantes com base na similaridade semÃ¢ntica, **reduzindo alucinaÃ§Ãµes** e garantindo respostas baseadas em dados reais.

---

## ğŸ§  O que esse projeto faz

* Armazena conteÃºdos textuais relacionados a comida
* Gera embeddings semÃ¢nticos (vetores de 384 dimensÃµes)
* Salva os vetores no PostgreSQL usando **pgvector**
* Executa **busca semÃ¢ntica** por similaridade vetorial
* ExpÃµe endpoints REST usando **FastAPI**
* Serve como base para um pipeline **RAG completo**

---

## ğŸ› ï¸ Tecnologias utilizadas

* **Python 3.11**
* **FastAPI**
* **Uvicorn**
* **PostgreSQL 15**
* **pgvector**
* **SQLAlchemy**
* **Sentence-Transformers** (embeddings)
* **Docker & Docker Compose**

---

## ğŸ“‚ Estrutura do projeto

```text
rag-comida/
â”œâ”€â”€ app/                 # Backend FastAPI
â”‚   â”œâ”€â”€ main.py          # Entrypoint, /health e /search
â”‚   â”œâ”€â”€ db/              # ConexÃ£o, modelos e init do pgvector
â”‚   â””â”€â”€ ...
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ ingest.py        # Script de ingestÃ£o usando all-MiniLM-L6-v2
â”œâ”€â”€ frontend/            # Frontend Next.js (chat UI)
â”‚   â”œâ”€â”€ app/page.js      # Chat com fetch para /search
â”‚   â””â”€â”€ app/layout.js
â”œâ”€â”€ docker-compose.yml   # Postgres + API
â”œâ”€â”€ Dockerfile           # Build da API
â”œâ”€â”€ requirements.txt     # DependÃªncias da API
â””â”€â”€ README.md
```

---

## âš™ï¸ PrÃ©-requisitos

Antes de comeÃ§ar, vocÃª precisa ter instalado:

* Python **3.11+**
* Docker
* Docker Compose
* Git

---

## ğŸ³ Subindo o banco com Docker

O projeto utiliza PostgreSQL com a extensÃ£o **pgvector** para armazenar e consultar embeddings vetoriais.

### 1ï¸âƒ£ Subir o container

Na raiz do projeto:

```bash
docker compose up -d
```

Isso irÃ¡ subir:

* PostgreSQL
* ExtensÃ£o **pgvector** jÃ¡ habilitada

---

### 2ï¸âƒ£ Acessar o banco (opcional)

```bash
docker exec -it vector_db psql -U postgres -d vector_db
```

### 3ï¸âƒ£ Ver logs em tempo real

```bash
docker compose logs -f api
```

---

## ğŸ” VariÃ¡veis de ambiente

Crie um arquivo `.env` baseado no exemplo:

```bash
cp .env.example .env
```

Exemplo de `.env`:

```env
DATABASE_URL=postgresql+psycopg2://postgres:postgres@localhost:5432/vector_db
```

---

## ğŸ Configurando o ambiente Python

### 1ï¸âƒ£ Criar e ativar o ambiente virtual

**Windows (PowerShell):**

```powershell
python -m venv venv
. venv\Scripts\Activate.ps1
```

**Linux / Mac:**

```bash
python -m venv venv
source venv/bin/activate
```

---

### 2ï¸âƒ£ Instalar dependÃªncias

```bash
python -m pip install -r requirements.txt
```

---

## ğŸš€ Rodando a aplicaÃ§Ã£o (API)

Com o ambiente virtual ativado (ou via container):

```bash
python -m uvicorn app.main:app --reload
```

Ou com Docker Compose:

```bash
docker compose up -d
```

A API fica em http://127.0.0.1:8000 (docs: http://127.0.0.1:8000/docs).

---

## â¤ï¸ Endpoint de saÃºde

Para validar se estÃ¡ tudo funcionando corretamente:

```http
GET /health
```

Resposta esperada:

```json
{ "status": "ok" }
```

---

## ğŸ§­ Frontend (Next.js + styled-components)

Interface de chat que consome `POST /search` da API.

### PrÃ©-requisitos
- Node 18+
- API rodando em http://localhost:8000 (ou defina `NEXT_PUBLIC_API_URL`)

### Setup
```bash
cd frontend
npm install
npm run dev
# abre em http://localhost:3000
```

Se a API estiver em outro host/porta, crie `frontend/.env.local`:
```
NEXT_PUBLIC_API_URL=http://localhost:8000
```

### Como funciona
- Header com tÃ­tulo e botÃ£o â€œLimpar chatâ€.
- Input e botÃ£o de envio travam enquanto o fetch estÃ¡ em andamento.
- Mensagens listadas em chat (usuÃ¡rio/bot).
- Faz `POST /search` com `{ query, top_k }` e responde com o documento mais relevante.

---

## ğŸ§  Fluxo RAG (resumo)

1. Textos culinÃ¡rios sÃ£o ingeridos na base
2. Cada texto gera um embedding vetorial
3. Os vetores sÃ£o armazenados no PostgreSQL
4. O usuÃ¡rio faz uma pergunta
5. A pergunta vira um embedding
6. O pgvector retorna os textos semanticamente mais prÃ³ximos
7. Esses textos podem ser usados por um LLM para gerar respostas confiÃ¡veis

---

## ğŸ§© PrÃ³ximas etapas do projeto

* [ ] ServiÃ§o de geraÃ§Ã£o de embeddings
* [ ] Endpoint de ingestÃ£o de documentos
* [ ] Endpoint de busca semÃ¢ntica
* [ ] IntegraÃ§Ã£o com LLM (RAG completo)
* [ ] Testes automatizados
* [ ] Frontend simples (chat ou busca)

---

## ğŸ“Œ ObservaÃ§Ã£o

Este projeto foi criado com foco **didÃ¡tico e prÃ¡tico**, servindo como base para estudos e aplicaÃ§Ãµes reais de **RAG com banco vetorial** usando pgvector.

---

ğŸš€ **Pronto! O projeto agora pode ser facilmente entendido, instalado e evoluÃ­do por qualquer pessoa do time.**
